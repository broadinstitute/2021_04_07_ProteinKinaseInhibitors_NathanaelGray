{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functools import partial, reduce\n",
    "import time\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/home/ubuntu/bucket/projects'\n",
    "proj_dir = '2018_11_20_GeneCpdFollowup'\n",
    "batch= '2018_11_20_Batch1'\n",
    "plates = ['BR00100032', 'BR00100037']\n",
    "\n",
    "outpath = '/home/ubuntu/bucket/projects/2018_11_20_GeneCpdFollowup/workspace/backend/2018_11_20_Batch1/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/bucket/projects/2018_11_20_GeneCpdFollowup/workspace/backend/2018_11_20_Batch1/BR00100032/BR00100032_selected_wells.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class load_data:\n",
    "    \n",
    "    def __init__(self,top_dir,proj_dir, batch, plates):\n",
    "        \n",
    "        self.top_dir = top_dir\n",
    "        self.proj_dir = proj_dir\n",
    "        self.batch = batch\n",
    "        self.plates = plates\n",
    "        \n",
    "\n",
    "    def sqlpath(self):\n",
    "        path = os.path.join(self.top_dir, self.proj_dir, 'workspace', 'backend', self.batch)\n",
    "        \n",
    "        spath = [os.path.join(path, p, p + \".sqlite\") for p in self.plates]\n",
    "        \n",
    "        return spath\n",
    "    \n",
    "    def csvpath(self):\n",
    "        \n",
    "        path = os.path.join(self.top_dir, self.proj_dir, 'workspace', 'backend', self.batch)\n",
    "        \n",
    "        spath = [os.path.join(path, p, p + \"selected_CDK14_ERK5.csv\") for p in self.plates]\n",
    "        \n",
    "        return spath\n",
    "    def dmsopath(self):\n",
    "        \n",
    "        path = os.path.join(self.top_dir, self.proj_dir, 'workspace', 'backend', self.batch)\n",
    "        \n",
    "        spath = [os.path.join(path, p, p + \"_selected_wells.csv\") for p in self.plates]\n",
    "        \n",
    "        return spath\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "path = load_data(top_dir, proj_dir, batch, plates)\n",
    "sqlpath = path.sqlpath()\n",
    "csvpath = path.csvpath()[0]\n",
    "dmsopath = path.dmsopath()\n",
    "dmsopath = dmsopath[0]\n",
    "dmsopath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlite_connect(path):\n",
    "    \n",
    "    engine = create_engine(os.path.join('sqlite:///'+path))\n",
    "    image = pd.read_sql_query(\"select *from Image\", engine)\n",
    "    cells = pd.read_sql_query(\"select  * from Cells\", engine)\n",
    "    cyto= pd.read_sql_query(\"select * from Cytoplasm\", engine)\n",
    "    nuclei= pd.read_sql_query(\"select * from Nuclei\", engine)\n",
    "    dt = reduce(lambda x,y: pd.merge(x,y, on=[\"TableNumber\", \"ImageNumber\", \"ObjectNumber\"], how='left'), [cells, nuclei, cyto])\n",
    "    df = reduce(lambda x,y: pd.merge(x,y, on=[\"TableNumber\", \"ImageNumber\"], how='left'), [dt, image])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "for spath, pl in zip(sqlpath, plates):\n",
    "    \n",
    "    df = sqlite_connect(spath)\n",
    "    selected_wells = ['F04', 'F08', 'F17', 'F21', 'G03', 'G04', 'G07', 'G08', 'G16',\n",
    "       'G17', 'G20', 'G21', 'H03', 'H04', 'H07', 'H08', 'H16', 'H17',\n",
    "       'H20', 'H21', 'I05', 'I06', 'I08', 'I09', 'I18', 'I19', 'I21',\n",
    "       'I22', 'J05', 'J06', 'J08', 'J09', 'J18', 'J19', 'J21', 'J22',\n",
    "       'K06', 'K09', 'K19', 'K22']\n",
    "    \n",
    "    df = df.query(\"Metadata_Well in @selected_wells\")\n",
    "    df.to_csv(os.path.join(outpath, pl, pl+'selected_FAK.csv'))\n",
    "\n",
    "finishtime = time.time()\n",
    "print('That took {} minutes'.format((finishtime - starttime)/60))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
